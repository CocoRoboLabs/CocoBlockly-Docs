# 第一章 認識物體識別
---

##  A.	圖像識別與計算機視覺
#####  1.	圖像識別
在學習物體識別前，我們先來認識下圖像識別。<br>
圖像識別，簡單地來說，就是一個將圖像與特定的詞語對應起來的過程。從技術上來看，是利用電腦對圖像進行處理、分析和理解，以識別各種不同模式的目標和對象的過程。圖像識別的發展經歷了三個階段：文字識別、數字圖像處理與識別、物體識別。<br>
文字識別的研究是從1950年開始的，一般是識別字母、數字和符號，從印刷文字識別到手寫文字識別，應用非常廣泛。<br>
<img src="/media/ai/AI_n1.png" width="300"/><img src="/media/ai/AI_n2.png" width="350"/><br>
數字圖像處理和識別的研究開始於1965年。數字圖像與模擬圖像相比具有存儲、傳輸方便可壓縮、傳輸過程中不易失真、處理方便等巨大優勢，這些都為圖像識別技術的發展提供了強大的動力。
<br><img src="/media/ai/AI_n3.png" width="350"/><br>
物體識別主要指對三維世界的物體及環境的感知和認識，屬於高級的計算機視覺範疇。它是以數字圖像處理與識別為基礎的結合人工智能、系統學等學科的研究方向，其研究成果被廣泛應用在各種工業及機器人中。
<br><img src="/media/ai/AI_n4.png" width="350"/><br>
瞭解了這些知識，我們再來看下面這四幅圖，第一張圖片是手寫數字，可以看到電腦將它正確地識別為了425，後三張圖片則分別分類為貓、人和車。
<br><img src="/media/ai/AI_n5.png" width="350"/><br>
這就是文字識別和物體識別的一些應用，電腦可通過深度學習算法，對輸入的圖像進行識別，並給出每幅圖片的識別結果。<br>
在人工智能領域，識別問題又可以歸類為分類問題，所以物體識別，也可以稱之為物體分類。<br>


#####  2.	計算機視覺
我們前面提到了，圖像識別就是電腦獲取，處理和分析圖像數據的過程，這個過程其實也就是計算機視覺的實現過程。簡而言之，計算機視覺使得電腦能夠“看”事物——甚至包括人類無法看到的事物。然而，要想讓電腦做到人類無法做到的事情，我們必須首先使電腦能夠做到人類可以做的事情：看到並標記物體和生物。這是圖像識別的主要功能。<br>
我們先來看下下面這四幅貓的圖片，我們可以很輕鬆地分辨出這四張圖片都是貓，即使它們外形長相完全不同，且體態各異，即使它只露出了一截尾巴，但我們仍然可以分辨的出來。<br>
但這對電腦來說卻十分困難，因為電腦並沒有像我們人類大腦這樣複雜的系統。
<br><img src="/media/ai/AI_n6.png" width="350"/><br>
那麼，到底電腦是如何識別圖片的呢？我們來看下一節內容。<br>

---
##  B.	神經網路與深度學習
電腦想要正確分類圖片，就需要像我們人類一樣去學習，知道圖片中大量的資訊。目前，最有可能讓電腦實現“看”的能力的技術叫做深度學習（Deep Learning，簡稱DL），它是一種讓電腦從圖片中學習的方法。學習的過程稱為訓練，識別的過程稱為推理（測試）。
<br><img src="/media/ai/AI_n7.png" width="350"/><br>
電腦要識別圖片，前提便是需要大量的圖片數據作為輸入，傳入電腦以供其學習。<br>
我們以識別貓為例，前期需要先準備大量的各種品類的貓，並且打上標籤，告訴電腦：這些是貓，也就是這些圖片的分類，然後電腦將這些數據輸入網路，執行訓練，通過不斷地迭代進行學習，達到正確認識這些貓的目的。<br>
然後，我們輸入電腦一張新的貓的圖片，進行測試，電腦執行測試演算法，便可給出輸入圖片的正確分類。<br>
這個過程就是電腦“看”事物（學習），並給出答案（識別）的過程。<br>
###### 我們再來看一下學術的解釋：
深度學習就是一種機器學習框架，通過模仿人類的神經元系統，為電腦提供自主學習能力。因此，電腦可以自動識別與發掘圖像數據的特徵，準確識別圖片中的內容，而無需根據指令或手動編碼來實現（但它需要大量的數據），並大大提高了計算精度及識別準確率。<br>
而模仿人類神經元系統的方法，在人工智能領域被稱為神經網路（Neural Networks）。<br>
下面，我們以圖像識別的入門級應用：MNIST手寫數字識別為例，來認識神經網路與深度學習的原理。其中，MNIST是一個手寫數字的圖片數據集。<br>

---
## C.	MNIST手寫數字識別
手寫識別是常見的圖像識別任務。電腦通過手寫體圖片來識別出圖片中的字，與印刷字體不同的是，不同人的手寫體風格迥異，大小不一， 造成了電腦對手寫識別任務的一些困難。 <br>
在研究過程中，數字手寫體識別由於其有限的類別（0~9共10個數字）成為了相對簡單的手寫識別任務。所以，我們從簡單的手寫數字識別入手，來認識實現圖像識別的演算法。<br>
##### 1.	人類學習和認識數字的過程
前面已經提到，電腦需要像人一樣思考學習，才能識別出圖像，我們不妨反推一下，想一想我們小時候是怎樣學習數字的，大家總結回想一下，我們學習數字的思維過程。為什麼我們可以看到各式各樣形狀的數字，依舊可以知道它們分別是多少呢？
<br><img src="/media/ai/AI_p1.png" width="350"/><br>
這個過程也就是電腦要模仿的，我們把這個學習步驟寫出來。
<br><img src="/media/ai/AI_p2.png" width="350"/><br>
這個就是人類學習和認知的過程，也就是機器要模仿的，現在我們將人的學習方式類比到電腦中，就會知道電腦學習並識別數字的過程了。
##### 2.	電腦學習並認識數字的過程
###### 1)	圖像在電腦中的樣子
我們向電腦輸入正確的帶有標籤的圖像數據，電腦看到的並不是像我們人類看到的那樣，如下圖左邊的圖片，而是下圖右邊數字矩陣的樣子。電腦中處理圖像，處理的是圖像中每一個像素（像素是電腦螢幕上所能顯示的最小單位，是用來表示圖像的單位）。
<br><img src="/media/ai/AI_p3.png" width="350"/><br>
上一節我們提到了，深度學習需要大量的數據作為輸入，在手寫數字識別系統中，數據來自於MNIST數據集，它包含60000個訓練集和10000測試數據集。分為圖片和標籤，圖片是28*28的像素矩陣，標籤為0~9共10個數字。
###### 2)	模型訓練——神經網路
有了數據集，下一步，便是將數據輸入到深度學習網路中，也就是神經網路中（這裏採用的是LeNet-5卷積神經網路模型，卷積神經網路是深度學習神經網路中最常見的一種），進行自動的特徵提取及學習，這個過程就是前面提到過的訓練過程。<br>
我們知道，人類大腦的神經網路是由神經元和突觸組成，它們協同工作，完成對外界資訊的處理與傳遞。
<br><img src="/media/ai/AI_p4.png" width="350"/><img src="/media/ai/AI_p5.png" width="350"/><br>
那麼，人腦的神經網路對比到深度學習中，就是如下圖所示的網路。
<br><img src="/media/ai/AI_p6.png" width="350"/><br>
大量的手寫數字圖像就是輸入數據，作為第一層：輸入層（一般情況下，輸入層不在網路結構中體現，而在後面訓練開始時給出），因為每張圖像的像素是28x28，所以每張圖像一共有784個像素，電腦中的索引一般從0開始，所以輸入x即為x0-x783。 <br>
中間部分稱為隱藏層，在LeNet-5網路中，主要採用的是：卷積層Convolutional Layer（啟動層為ReLu Layer）、池化層Pooling Layer以及全連接層Fully Connected Layer。<br>
全連接層中加入啟動函數：Softmax，這是一個回歸模型，用於分類過程，可解決多分類問題。這裏的手寫數字識別就是一個多分類問題，0-9共10類，所以最後的輸出層y的結果為y0~y9。
<br><img src="/media/ai/AI_p7.png" width="350"/><br>
並且Softmax也是一個概率函數，它可以給出輸入圖像識別為不同類別的概率，以此來讓使用者判斷輸入圖像中的數字更像哪一個識別結果。<br>
這部分就是神經網路的網路結構，是深度學習演算法實現圖像處理及學習的根本。
###### 3)	人類學習過程和電腦學習過程的對比
前面我們給出了人類學習和認識數字的過程，也就是下圖左邊的部分，通過上一節的學習，我們知道了電腦學習並認識數字的過程，那麼總結起來，就是下圖右邊所示的步驟。
<br><img src="/media/ai/AI_p8.png" width="350"/><br>
###### 4)	手寫數字識別的實現演示
我們知道了手寫數字識別的原理，那麼，現在就來看看實際電腦中是如何實現圖像識別的吧。
打開網址：https://ai-blockly.cocorobo.hk/ ，進入AI blockly頁面。<br>
進入後，首先選擇Examples選項。
<br><img src="/media/ai/AI_p9.png" width="350"/><br>
然後，繼續選擇Tensor Flow選項，然後選擇Digit Recognition選項，並選擇OK。
<br><img src="/media/ai/AI_p10.png" width="350"/><img src="/media/ai/AI_p11.png" width="350"/><br>
然後，就會出現如下圖所示的積木程式塊。
<br><img src="/media/ai/AI_p12.png" width="350"/><br>
繼續點擊右下角區域中的RUN按鈕，即可開始訓練。
<br><img src="/media/ai/AI_p13.png" width="350"/><br>
訓練的迭代過程中，會產生如下圖所示的函數曲線圖及網路結構資訊（Model Architecture），可通過觀察曲線圖的變化，來判斷訓練執行的狀態及模型的訓練效果。
<br><img src="/media/ai/AI_p14.png" width="350"/><br>
如上圖所示，是演示的最終效果，左邊是曲線圖，第一副圖是訓練集（loss）和驗證集（val_loss）的loss變化曲線，loss是損失函數，即模型預測出的結果與標籤標注的真實值的差值。這個差值是隨著訓練輪數Epoch的增加而逐漸減小的。<br>
第二幅圖是訓練集（acc）和驗證集（val_acc）的準確率變化曲線，準確率為識別正確的圖像個數除以總的圖像數的比值，該值隨著Epoch的增加而逐漸增大。<br>
右側為推理測試區，在畫布中寫出你要測試的數字，點擊Detect，即可得到最終的識別結果。<br>
其結果將打印顯示在右上方區域的Console中。
<br><img src="/media/ai/AI_p15.png" width="350"/><img src="/media/ai/AI_p16.png" width="350"/><br>
手寫數字識別的整個實現過程到這裏就結束了。<br>
接下來，我們來學習今天最重要的部分——物體識別。

---
## D.	物體識別與YOLO演算法
物體識別（Object Recognition）是計算機視覺中的一個應用，目的是讓電腦去分析一張圖片或者一段影片中的物體，並標注出其中物體所屬的類別。
<br><img src="/media/ai/AI_q1.png" width="350"/><br>
###### YOLO演算法介紹：
YOLO演算法，是目前應用非常廣泛的一種物體識別演算法。YOLO的意思是You only look once，也就是你只看一眼，就能認出這是什麼物體，體現YOLO演算法識別的精度和速度。<br>
YOLO是基於Pascal VOC2012數據集的目標檢測系統。它能夠檢測到20種Pascal的目標類別，包括：<br>
- 人
- 鳥，貓，牛，狗，馬，羊
- 飛機，自行車，船，汽車，摩托車，火車
- 瓶子，椅子，桌子，盆栽植物，沙發，電視或者顯示器<br>
YOLO演算法目前最新的已經迭代到了v4版本，各個版本的應用場景都是相同的，區別只在於識別精度及速度。這裏，視頻中展示的是YOLOv3的應用及識別結果，但這並不影響學習，我們這裏主要講的是入門級的YOLOv1的原理。<br>
YOLO演算法的識別過程分為兩個部分，這也基本是所有視覺領域內的深度學習演算法的實現過程。<br>
1.  訓練圖像數據，迭代過程優化參數，獲得最終模型；
2.  輸入新的圖像數據，調用模型，實現推理（inference）過程，也稱為測試過程。
我們先來看下第一步的原理：<br>
訓練就需要有網路，YOLO的網路結構如下圖所示，整個檢測網路包括24個卷積層和2個全連接層。其中，卷積層用來提取圖像特徵，全連接層用來預測圖像位置和類別概率值。
<br><img src="/media/ai/AI_q3.png" width="350"/><br>
第二步：推理過程：
<br><img src="/media/ai/AI_q4.png" width="350"/><br>
加載網路模型後，其推理的計算流程如圖所示，我們可以將最終識別結果之前的步驟都看做一個函數計算，通過這個計算過程，就可以得到最後的物體識別結果了。<br>
那麼，YOLO具體是如何實現物體識別的呢？我們來深入地學習一下它的內部原理。
<br><img src="/media/ai/AI_q5.png" width="350"/><br>
如上圖所示，YOLO演算法將輸入圖片劃分成7x7=49個網格（即上圖中左邊第一副圖，S=7），如果一個物體的中心落在某網格(cell)內，則相應網格負責檢測該物體。<br>
每個網格預測兩個邊界框（Bounding boxes），一共預測49x2=98個邊界框（上圖中位於上面的那副圖）。可以近似理解為在輸入圖片上粗略的選取98個候選區，這98個候選區覆蓋了圖片的整個區域，進而用回歸預測這98個候選框對應的邊界框。<br>
除了給出邊界框，也就是圖像的位置資訊外，還會給出對應的置信度（confidence）和分類結果（categories）。其中，置信度代表了所預測的 box 中含有 object 的置信度（概率）和這個 box 預測目標位置的準確度這兩重資訊。<br>
最後，網路就給出了圖像的最終識別結果，如下圖所示。
<br><img src="/media/ai/AI_q6.png" width="350"/><br>

---
## E.	AI模型積木說明
在學習瞭解了深度學習與物體識別的原理之後，我們開始積木程式塊的學習，將理論與實踐相結合，才能更好地學習並認識物體識別。
<table style="margin-top:20px;">
	<tr>
		<td width="50%">積木</td>
		<td width="20%">指令</td>
    <td width="30%">說明</td>
	</tr>
  <tr>
    <td width="50%"><img src="/media/ai/AI_r1.png" width="300"/></td>
    <td width="20%">載入模型</td>
    <td width="30%">載入人工智能模型，可以從選單中選擇常用識別模型<img src="/media/ai/AI_r2.png" width="300"/></td>
  </tr>
  <tr>
    <td width="50%"><img src="/media/ai/AI_r3.png" width="300"/></td>
    <td width="20%">獲取識別結果</td>
    <td width="30%">獲取當前結果，可選擇數字識別的結果或者識別為某個數字的置信度<img src="/media/ai/AI_r4.png" width="300"/>置信度：識別為某個類別的概率</td>
  </tr>
  <tr>
    <td width="50%"><img src="/media/ai/AI_r5.png" width="300"/></td>
    <td width="20%">物體識別</td>
    <td width="30%">獲取物體識別真假值，如果識別到物體會返回「真」值，否則返回「假」值</td>
  </tr>
  <tr>
    <td width="50%"><img src="/media/ai/AI_r6.png" width="300"/></td>
    <td width="20%">物體識別結果的參數</td>
    <td width="30%">獲取識別到的每個物體的各項參數，包括：<img src="/media/ai/AI_r7.png" width="300"/></td>
  </tr>
  <tr>
    <td width="50%"><img src="/media/ai/AI_r8.png" width="300"/></td>
    <td width="20%">人臉識別</td>
    <td width="30%">獲取人臉識別真假值，如果識別到人臉會返回「真」值，否則返回「假」值</td>
  </tr>
  <tr>
    <td width="50%"><img src="/media/ai/AI_r9.png" width="300"/></td>
    <td width="20%">人臉識別結果的參數</td>
    <td width="30%">獲取識別到的每個人臉的各項參數，包括：<img src="/media/ai/AI_r10.png" width="300"/></td>
  </tr>
<tr>
    <td width="50%"><img src="/media/ai/AI_r11.png" width="300"/></td>
    <td width="20%">加載客制化模型</td>
    <td width="30%">從指定路徑加載用戶預訓練好的客制化模型：/sd/user/mymodel.kmodel
並根據要識別的物體種類來設定客制化物體的類別名稱：Object Name
</td>
  </tr>
<tr>
    <td width="50%"><img src="/media/ai/AI_r12.png" width="300"/></td>
    <td width="20%">客制化的物體識別</td>
    <td width="30%">獲取客制化物體識別真假值，如果識別到客制化物體會返回「真」值，否則返回「假」值</td>
  </tr>
<tr>
    <td width="50%"><img src="/media/ai/AI_r13.png" width="300"/></td>
    <td width="20%">客制化物體識別結果的參數</td>
    <td width="30%">獲取識別到的每個客制化物體的各項參數，包括：<img src="/media/ai/AI_r14.png" width="300"/></td>
  </tr>
</table>

---
## F.	基礎編程
##### 活動一：物體檢測並顯示識別結果在「串口互動窗」
<table style="margin-top:20px;">
<tr>
  <td colspan=2>在積木指令區點按以下指令，並依次放在積木編程區：<br>
1.	AI模組｜圖像處理：【相機初始化】<br>
2.	循環：【一直重複執行】<br>
3.	AI模組｜AI模型：【加載預設模型】<br>
選擇：模型：「常見物體檢測模型」  圖像：「img_objectrecognition」<br>
4.	變數：【設定變數】img_objectrecognition<br>
5.	AI模組｜相機：【獲取相機捕捉的圖像】<br>
6.	邏輯：【邏輯判斷】<br>
7.	AI模組｜模型：【識別到了任意常見物體】<br>
8.	序列埠通訊｜打印：【打印文字】<br>
識別到物體則顯示「Object Detected」，否則「Nothing Detected」<br>
</td>
</tr>
<tr >
<td><img src="/media/ai/AI_s1.png" width="300"/></td>
<td>注意：步驟4必須使用內建變數「img_objectrecognition」，所以首先要在步驟3使用「加載預設模型」指令，然後才進行步驟4及步驟5。</td>
</tr>
<tr >
<td><img src="/media/ai/AI_s2.png" width="300"/></td>
<td><img src="/media/ai/AI_s3.png" width="300"/></td>
</tr>
<tr >
<td>測試結果：在「代碼區」點按「串口互動窗」，將模組向四周掃描，並觀察顯示的結果如下，當檢測到有物體時會顯示「Object Found」，否則會顯示「Nothing」</td>
<td><img src="/media/ai/AI_s4.png" width="300"/></td>
</tr>
</table>

##### 活動二：物體檢測並顯示物體名稱
<table style="margin-top:20px;">
<tr>
  <td colspan=2>重複活動一的程式，在步驟8「顯示文字」指令修改如下：<br>
1.	循環：【For循環】<br>
2.	AI模組｜模型：【識別到了任意常見物體】<br>
3.	序列埠通訊：【打印】<br>
4.	AI模組｜模型：【獲取物體參數】選擇「物體名稱」<br>
</td>
</tr>
<tr >
<td colspan=2><img src="/media/ai/AI_s5.png" width="300"/></td>
</tr>
<tr >
<td><img src="/media/ai/AI_s6.png" width="300"/></td>
<td><img src="/media/ai/AI_s7.png" width="300"/></td>
</tr>
<tr >
<td>測試結果：點按「串口互動窗」，將模組向四周掃描，並觀察顯示的結果如下，當檢測到有物體時會顯示「物體名稱」，否則會顯示「Nothing」</td>
<td><img src="/media/ai/AI_s8.png" width="300"/></td>
</tr>
</table>
思考問題：活動二的程式運用「物體檢測模型」，判斷攝影鏡頭拍攝到的圖像，並輸出物體名稱，此名稱是如何決定？「物體檢測模型」是否能夠判斷所有物體，輸出正確名稱？
<br><img src="/media/ai/AI_s9.png" width="300"/>

---
## G.	專題學習
硬體設備：AI推理模組、螢幕模組、攝像頭模組<br>
任務目標：利用攝影鏡頭將影像顯示在螢幕模組上，載入物體識別模型，將識別到的物體在螢幕上標示出來。<br>
基本流程/步驟：
<br><img src="/media/ai/AI_t1.png" width="350"/><br>

###### 第一步：模組初始化
<table style="margin-top:20px;">
<tr >
<td>在積木指令區點按以下指令，並依次放在積木編程區：<br>
1.	AI模組｜螢幕：【初始化】<br>
2.	AI模組｜相機：【初始化】<br>
3.	循環：【重複執行】<br>
</td>
<td><img src="/media/ai/AI_t2.png" width="300"/></td>
</tr>
</table>

###### 第二步：獲取影像，載入物體識別模型，進行物體識別
<table style="margin-top:20px;">
<tr>
  <td colspan=2>在【重複執行】積木指令內，放置下列積木指令：<br>
4.	AI模組｜AI模型：【加載模型】<br>
(模型：常見物體識別模型 圖像：img_objectrecognition)<br>
5.	變數：【賦值】(名稱：img_objectrecognition)<br>
6.	AI模組｜相機：【獲取影像】<br>
7.	變數：【建立變數】(名稱：img_display)<br>
8.	AI模組｜圖像處理：【調整畫布尺寸】<br>
9.	AI模組｜圖像處理：【圖像轉換】<br>
</td>
</tr>
<tr >
<td colspan=2><img src="/media/ai/AI_t3.png" width="300"/></td>
</tr>
<tr >
<td><img src="/media/ai/AI_t4.png" width="300"/></td>
<td><img src="/media/ai/AI_t5.png" width="300"/></td>
</tr>
</table>

###### 第三步：獲取影像，載入物體識別模型，進行物體識別
<table style="margin-top:20px;">
<tr>
  <td colspan=2>在【圖像轉換】積木指令之後，放置下列積木指令：<br>
10.	邏輯：【邏輯判斷】<br>
11.	AI模組｜AI模型：【物體識別】<br>
12.	循環：【For循環】<br>
13.	AI模組｜AI模型：【物體識別】<br>
14.	AI模組｜圖像處理：【螢幕文字】，並修改座標的X值及Y值，使「物體名稱」顯示在螢幕左上角的適宜位置<br>
15.	文字：【建立字串使用】<br>
16.	AI模組｜模型：【獲取物體參數】選擇「物體名稱」<br>
17.	AI模組｜圖像處理：【螢幕文字】並輸入「Nothing Detected.」，並修改座標的X值及Y值<br>

</td>
</tr>
<tr >
<td colspan=2><img src="/media/ai/AI_t6.png" width="300"/></td>
</tr>
<tr >
<td colspan=2><img src="/media/ai/AI_t7.png" width="300"/></td>
</tr>
</table>

###### 第四步：在螢幕上顯示影像
<table style="margin-top:20px;">
<tr>
  <td colspan=2>在步驟10【邏輯判斷】積木指令之後，放置下列積木指令：<br>
18.	AI模組｜螢幕：【設定起始點坐標】、【顯示畫布】(名稱：img_display  起始座標X：8   Y值：36)
</td>
</tr>
<tr >
<td colspan=2><img src="/media/ai/AI_t8.png" width="300"/></td>
</tr>
</table>

###### 完整程式：
<table style="margin-top:20px;">
<tr>
 <td ><img src="/media/ai/AI_t9.png" width="300"/>
</td>
</tr>
<tr >
<td><img src="/media/ai/AI_t10.png" width="200"/></td>
</tr>
</table>

---
## H.	專題學習進階
<img src="/media/ai/AI2_A1.png" width="400"/><br>
<img src="/media/ai/AI2_A2.png" width="400"/><br>
上面左圖為AI基礎篇簡易物體識別的功能，在此基礎上增加以下內容：在螢幕中顯示識別到的物體位置，以檢測框的形式標註出來，並在螢幕上方打印物體名稱，結果如上面右圖所示。
###### 第一步：模組初始化

<table style="margin-top:20px;">
<tr>
  <td >在積木指令區點按以下指令，並依次放在積木編程區：<br>
1. AI模組｜螢幕：【初始化】<br>
2. AI模組｜相機：【初始化】<br>
3. AI模組｜螢幕：【建立畫布】、【設定起始點座標】<br>
4. 循環：【重複執行】
<br>
</td>
<td ><img src="/media/ai/AI2_A3.png" width="400"/></td>
</tr>
</table>

###### 第二步：獲取影像，載入物體識別模型，進行物體識別

<table style="margin-top:20px;">
<tr>
<td >在【重複執行】積木指令內，放置下列積木指令：<br>
5. AI模組｜AI模型：【加載模型】<br>(模型：常見物體識別模型 圖像：img_objectrecognition)<br>
6. 變數：【賦值】(名稱：img_objectrecognition)<br>
7. AI模組｜相機：【獲取影像】<br>
8. 變數：【建立變數】(名稱：img_display)<br>
9. AI模組｜圖像處理：【調整畫布尺寸】<br>
10. AI模組｜圖像處理：【圖像轉換】<br>
</td>
</tr>
<tr>
  <td ><img src="/media/ai/AI2_A4.png" width="400"/>
</td>
</tr>
</table>

###### 第三步：識別物體，若識別到，則在待識別物體周圍顯示白色矩形檢測框，並在屏幕上方打印出該物體名稱。

<table style="margin-top:20px;">
<tr>
<td >在【圖像轉換】積木指令內，放置下列積木指令：<br>
11. 邏輯：【邏輯判斷】，添加【否则】项目<br>
12. AI模組｜AI模型：【物體識別】<br>
13. 循環：【For循環】<br>
14. AI模組｜AI模型：【物體識別】<br>
15. AI模組｜螢幕：【繪製矩形】（畫布：object  空心  白色  厚度2）
起始座標：X值，Y值   尺寸：寬度，高度<br>
&nbsp a.	數學運算：【int】轉換整數<br>
&nbsp b.	數學運算：【四則運算】，物體識別數值 / 1.42<br>
&nbsp c.	AI模組｜AI模型：【物體識別屬性】<br>
16. AI模組｜螢幕：【繪製矩形】（畫布：obj_name  實心  黑色  厚度1 宽高(240，31)）<br>
17. AI模組｜螢幕：【繪制文字】需建立字串接收待打印的物體名稱（畫布：obj_name）
</td>
</tr>
<tr>
  <td ><img src="/media/ai/AI2_A5.png" width="400"/>
</td>
</tr>
</table>

注意：
上圖中，X、Y位置顯示積木塊過長，為了編寫程式時方便查看，我們可以使用如下操作：<br>
1. 選中較長的顯示區域<br>
<img src="/media/ai/AI2_A6.png" width="300"/>
2. 點擊右鍵，看到如下菜單，選擇【外部輸入】：<br>
<img src="/media/ai/AI2_A7.png" width="200"/>
3. 即可改變積木塊的排列方式：<br>
<img src="/media/ai/AI2_A8.png" width="300"/>
<img src="/media/ai/AI2_A9.png" width="300"/>

###### 第四步：在螢幕上顯示影像

<table style="margin-top:20px;">
<tr>
  <td >在步驟11【邏輯判斷】的【否则】積木指令中，放置下列積木指令：<br>
18. AI模組｜螢幕：【繪製矩形】（畫布：obj_name 實心  黑色  厚度1 宽高(240，31)）<br>
19. AI模組｜螢幕：【繪制文字】<br>
20. AI模組｜螢幕：【設定起始座標】、【顯示畫布】(object)、【顯示畫布】(名稱：obj_name  起始座標X：8   Y值：36)
</td>
</tr>
<tr >
<td> <img src="/media/ai/AI2_A10.png" width="400"/></td>
</tr>
<tr >
<td> 完整Python代碼：<br><img src="/media/ai/AI2_A11.png" width="400"/></td>
</tr>
<tr >
<td> 完整程式：<br><img src="/media/ai/AI2_A12.png" width="400"/></td>
</tr>
<tr >
<td> 運行結果：<br><img src="/media/ai/AI2_A13.png" width="200"/><img src="/media/ai/AI2_A14.png" width="200"/><img src="/media/ai/AI2_A15.png" width="200"/></td>
</tr>
</table>
